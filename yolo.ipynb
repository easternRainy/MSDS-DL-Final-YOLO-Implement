{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "listed-semiconductor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "exterior-chinese",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    df_train = pd.read_csv(\"data/train.csv\")\n",
    "    df_valid = pd.read_csv(\"data/test.csv\")\n",
    "    \n",
    "    return df_train, df_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "deadly-might",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tiny():\n",
    "    df_tiny = pd.read_csv(\"data/8examples.csv\")\n",
    "    \n",
    "    return df_tiny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "attached-prior",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tiny = load_tiny()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "streaming-tenant",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLODataset(Dataset):\n",
    "    \"\"\"\n",
    "    - No data augmentation because there are so many bugs in Albumentation\n",
    "    - S: split an image by (S x S)\n",
    "    - B: the number of box in an image\n",
    "    - C: number of classes\n",
    "    \"\"\"\n",
    "    def __init__(self, df, S=7, B=2, C=20, img_size=448, img_dir=\"data/images\", label_dir=\"data/labels\"):\n",
    "        self.df = df\n",
    "        self.S = S\n",
    "        self.B = B\n",
    "        self.C = C\n",
    "        self.img_dir = img_dir\n",
    "        self.label_dir = label_dir\n",
    "        \n",
    "        self.resize = transforms.Resize((img_size, img_size))\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self._load_image(idx)\n",
    "        boxes = self._load_boxes(idx)\n",
    "        label_matrix = self._load_label_matrix(boxes)\n",
    "        \n",
    "        return image, label_matrix\n",
    "        \n",
    "        \n",
    "    def _load_image(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.df.iloc[idx][\"img\"])\n",
    "        image = Image.open(img_path)\n",
    "        image = self.resize(image)\n",
    "        image = self.to_tensor(image)\n",
    "        \n",
    "        return image\n",
    "    \n",
    "    \n",
    "    def _load_boxes(self, idx):\n",
    "        \"\"\"\n",
    "        read box files, get a list of boxes\n",
    "        each box is formated as [class_label, x, y, width, height]\n",
    "        \"\"\"\n",
    "        label_path = os.path.join(self.label_dir, self.df.iloc[idx]['label'])\n",
    "        \n",
    "        boxes = []\n",
    "        with open(label_path) as f:\n",
    "            for label in f.readlines():\n",
    "                class_label, x, y, width, height = label.split()\n",
    "                box = [int(class_label), float(x), float(y), float(width), float(height)]\n",
    "                boxes.append(box)\n",
    "            \n",
    "        return boxes\n",
    "    \n",
    "    \n",
    "    def _load_label_matrix(self, boxes):\n",
    "        \"\"\"\n",
    "        convert a list of boxes [[...], [...], [...]]\n",
    "        to tensor of shape (S, S, C+5B), where SxS is the split of image\n",
    "        5 means (probability_of_some_class, x, y, width, height)\n",
    "        \"\"\"\n",
    "        label_matrix = torch.zeros((self.S, self.S, self.C+5*self.B))\n",
    "        for box in boxes:\n",
    "            # convert each box to fit the label matrix \n",
    "            \n",
    "            class_label, x, y, width, height = box\n",
    "            \n",
    "            # which cell in (S x S) split does the center (x, y) belongs to\n",
    "            i = int(self.S * y)\n",
    "            j = int(self.S * x)\n",
    "            \n",
    "            # what is coordinate does the center in the cell (i, j)\n",
    "            cell_x = self.S * x - j\n",
    "            cell_y = self.S * y - i\n",
    "            \n",
    "            # what is the relative with and height of the box if\n",
    "            # assuming the width and height of each cell in (S x S) split is 1?\n",
    "            width_cell = width * self.S\n",
    "            height_cell = height * self.S\n",
    "            \n",
    "            if label_matrix[i, j, 20] == 0:\n",
    "                label_matrix[i, j, 20] = 1 # for computing loss, the probability is 1\n",
    "                label_matrix[i, j, class_label] = 1\n",
    "                box_coord = torch.tensor([cell_x, cell_y, width_cell, height_cell])\n",
    "                label_matrix[i, j, 21:25] = box_coord\n",
    "                \n",
    "        return label_matrix    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "macro-tracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = YOLODataset(df_tiny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "desperate-latitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(ds, batch_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "becoming-broadcast",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG, LABEL = next(iter(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "indoor-oriental",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3, 448, 448])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMG.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "metallic-paint",
   "metadata": {},
   "outputs": [],
   "source": [
    "from yolo import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "specific-collective",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Yolo(split_size=7, num_boxes=2,num_classes=20)\n",
    "out = model(IMG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "tamil-sender",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1470])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agreed-equality",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
